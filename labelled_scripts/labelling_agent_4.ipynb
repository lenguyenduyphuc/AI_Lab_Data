{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203e9b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert annotator responsible for labeling online messages to support AI systems that detect mental health risks, predatory behavior, and emotional distress. Your output will be used to train models for real-time safety monitoring.\n",
    "\n",
    "Objective: Create high-quality labeled data for training AI models that can detect predatory behaviors, emotional distress, and mental health risks in online communications.\n",
    "\n",
    "===========================\n",
    "1) Label Set (Choose one or more)\n",
    "===========================\n",
    "\n",
    "• Suicidal Reference\n",
    "  - Mentions or implies suicidal thoughts, ideation, or self-harm\n",
    "  - Example: \"Sometimes I think about ending it all.\"\n",
    "\n",
    "• Emotional Distress\n",
    "  - Signs of depression, anxiety, emotional suffering, psychological struggle\n",
    "  - Example: \"I just feel so lost lately, like nothing matters.\"\n",
    "\n",
    "• Attacking Behavior\n",
    "  - Bullying, sexually predatory content, threats, grooming, or intimidation\n",
    "  - Example: \"Don't tell your parents — it's our secret, okay?\"\n",
    "\n",
    "• Safe/Neutral\n",
    "  - No concerning behavior, emotionally balanced, or informative\n",
    "  - Example: \"I got an A on my exam! So happy right now!\"\n",
    "\n",
    "• Unclear\n",
    "  - Too vague or ambiguous to confidently assign a label\n",
    "  - Example: \"I'm fine.\" (without context)\n",
    "\n",
    "===========================\n",
    "2) Labeling Instructions\n",
    "===========================\n",
    "\n",
    "• Carefully read the message.\n",
    "• Assign one or more appropriate labels from the Label Set.\n",
    "• If the message is vague or lacks sufficient context, assign the 'Unclear' label.\n",
    "• Respond **only** in JSON format with the keys: \"labels\" (list of strings).\n",
    "• IMPORTANT: Always return labels as an array of strings, even for single labels.\n",
    "\n",
    "--- Example Output Format ---\n",
    "{\"labels\": [\"Emotional Distress\"]}\n",
    "{\"labels\": [\"Attacking Behavior\"]}\n",
    "{\"labels\": [\"Suicidal Reference\"]}\n",
    "{\"labels\": [\"Safe/Neutral\"]}\n",
    "{\"labels\": [\"Unclear\"]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733960f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CONFIG ──────────────────────────────────────────────────────────────────────\n",
    "INPUT_FILE = Path(\"toxicity_parsed.xlsx\")      \n",
    "OPENAI_MODEL = \"deepseek/deepseek-r1:free\"\n",
    "CHUNK_SIZE   = 10                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc42474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str) -> dict:\n",
    "    KEY = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=KEY,\n",
    "    )\n",
    "    try:\n",
    "        clean_text = str(text).strip()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            temperature=0,\n",
    "            extra_body={},\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": clean_text}\n",
    "            ],\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content\n",
    "        result = json.loads(response_content)\n",
    "        return {\"labels\": result[\"labels\"]}\n",
    "    except Exception as e:\n",
    "        print(f\"API error: {e}\")\n",
    "        return {\"labels\": [\"Unclear - API Error\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f5307a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    print(f\"Loading data from {INPUT_FILE}…\")\n",
    "    try:\n",
    "        all_sheets = pd.read_excel(INPUT_FILE, sheet_name=None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Gather every \"body\" column we can find\n",
    "    bodies = (\n",
    "        pd.concat(\n",
    "            [df[\"body\"] for df in all_sheets.values() if \"body\" in df.columns],\n",
    "            ignore_index=True\n",
    "        )\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "    )\n",
    "\n",
    "    # subset_df = bodies.iloc[:8500].reset_index(drop=True).to_frame(name=\"body\")\n",
    "    # subset_df[\"labels\"] = \"\"  # placeholder column\n",
    "    # total_rows = len(subset_df)\n",
    "    # print(f\"Selected {total_rows} messages for labelling.\")\n",
    "    subset_df = bodies.reset_index(drop=True).to_frame(name=\"body\")\n",
    "    subset_df[\"labels\"] = \"\"  # placeholder column\n",
    "    total_rows = len(subset_df)\n",
    "    print(f\"Selected {total_rows} messages for labelling.\")\n",
    "\n",
    "    # Pre-compute filenames\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_outfile = INPUT_FILE.with_name(f\"Toxicity_parsed_labelled_{ts}.xlsx\")\n",
    "    progress_file = INPUT_FILE.with_name(f\"Toxicity_parsed_labelled_cp_{ts}.xlsx\")\n",
    "\n",
    "    print(\"Starting labelling process…\")\n",
    "    \n",
    "    for idx, msg in enumerate(tqdm(subset_df[\"body\"], desc=\"Labelling\", total=total_rows), 1):\n",
    "        time.sleep(0.2) \n",
    "        \n",
    "        # Get labels for the message\n",
    "        rec = label_text(msg)\n",
    "        labels_list = rec.get(\"labels\", [\"Unclear - Processing Error\"])\n",
    "        subset_df.at[idx - 1, \"labels\"] = \", \".join(labels_list)\n",
    "\n",
    "        # Checkpoint save\n",
    "        if idx % CHUNK_SIZE == 0 or idx == total_rows:\n",
    "            try:\n",
    "                subset_df.iloc[:idx].to_excel(progress_file, index=False)\n",
    "                print(f\"✓ Checkpoint: ({idx}/{total_rows}) ➜ {progress_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not save checkpoint: {e}\")\n",
    "\n",
    "    # Final save\n",
    "    try:\n",
    "        subset_df.to_excel(final_outfile, index=False)\n",
    "        print(f\"✓ Finished. Full file saved ➜ {final_outfile}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b74cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from toxicity_parsed.xlsx…\n",
      "Selected 159675 messages for labelling.\n",
      "Starting labelling process…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfa021147ae49d891793a4b9b2d6351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labelling:   0%|          | 0/159675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'OPENROUTER_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     36\u001b[39m time.sleep(\u001b[32m0.2\u001b[39m) \n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Get labels for the message\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m rec = \u001b[43mlabel_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m labels_list = rec.get(\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mUnclear - Processing Error\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     41\u001b[39m subset_df.at[idx - \u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(labels_list)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mlabel_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlabel_text\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     KEY = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENROUTER_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m     client = OpenAI(\n\u001b[32m      4\u001b[39m         base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://openrouter.ai/api/v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m         api_key=KEY,\n\u001b[32m      6\u001b[39m     )\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:716\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'OPENROUTER_API_KEY'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
